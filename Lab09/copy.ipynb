{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "print(\"My device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=10),  \n",
    "    transforms.RandomAffine(degrees=20, translate=(0.1, 0.1), scale=(0.85, 1.15)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, partition = \"train\", transform=None):\n",
    "\n",
    "        print(\"\\nLoading MNIST \", partition, \" Dataset...\")\n",
    "        self.partition = partition\n",
    "        self.transform = transform\n",
    "        if self.partition == \"train\":\n",
    "            self.data = torchvision.datasets.MNIST('.data/', train=True, download=True)\n",
    "        else:\n",
    "            self.data = torchvision.datasets.MNIST('./data/', train=False, download=True)\n",
    "        print(\"\\tTotal Len.: \", len(self.data), \"\\n\", 50*\"-\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        image = self.data[idx][0]\n",
    "        image = self.transform(image)\n",
    "        image = image.view(-1)\n",
    "\n",
    "        label = torch.tensor(self.data[idx][1])\n",
    "        label = F.one_hot(label, num_classes=10).float()\n",
    "\n",
    "        return {\"idx\": idx, \"img\": image, \"label\": label}\n",
    "\n",
    "train_dataset = MNIST_dataset(partition=\"train\", transform=train_transform)\n",
    "test_dataset = MNIST_dataset(partition=\"test\", transform=test_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_workers = 0\n",
    "print(\"Num workers\", num_workers)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, sizes=[[784, 1024], [1024, 1024], [1024, 1024], [1024, 10]], criterion=None):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        for i in range(len(sizes)-1):\n",
    "            dims = sizes[i]\n",
    "            self.layers.append(nn.Linear(dims[0], dims[1]))\n",
    "            self.layers.append(nn.BatchNorm1d(dims[1]))\n",
    "            self.layers.append(nn.ReLU())\n",
    "\n",
    "        dims = sizes[-1]\n",
    "        self.classifier = nn.Linear(dims[0], dims[1])\n",
    "\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        if y != None:\n",
    "            loss = self.criterion(x, y)\n",
    "            return loss, x\n",
    "        return x\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_classes = 10\n",
    "net = Net(sizes=[[784, 1024], [1024, 1024], [1024, 1024], [1024, num_classes]], criterion=criterion)\n",
    "print(net)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Params: \", count_parameters(net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.1, weight_decay=1e-6, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[25, 50], gamma=0.1)\n",
    "\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 27\n",
    "\n",
    "print(\"\\n---- Start Training ----\")\n",
    "best_accuracy = -1\n",
    "best_epoch = 0\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # TRAIN NETWORK\n",
    "    train_loss, train_correct = 0, 0\n",
    "    net.train()\n",
    "    with tqdm(iter(train_dataloader), desc=\"Epoch \" + str(epoch), unit=\"batch\") as tepoch:\n",
    "        for batch in tepoch:\n",
    "\n",
    "          images = batch[\"img\"].to(device)\n",
    "          labels = batch[\"label\"].to(device)\n",
    "          ids = batch[\"idx\"].to('cpu').numpy()\n",
    "\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          #  Forward\n",
    "          loss, outputs = net(images, labels)\n",
    "\n",
    "          loss.backward()\n",
    "\n",
    "          optimizer.step()\n",
    "\n",
    "          # one hot -> labels\n",
    "          labels = torch.argmax(labels, dim=1)\n",
    "          pred = torch.argmax(outputs, dim=1)\n",
    "\n",
    "          train_correct += pred.eq(labels).sum().item()\n",
    "\n",
    "          # print statistics\n",
    "          train_loss += loss.item()\n",
    "\n",
    "        scheduler.step()\n",
    "        print(\"\\tLR: \", optimizer.param_groups[0]['lr'])\n",
    "\n",
    "    train_loss /= len(train_dataloader.dataset)\n",
    "\n",
    "    # TEST NETWORK\n",
    "    test_loss, test_correct = 0, 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "      with tqdm(iter(test_dataloader), desc=\"Test \" + str(epoch), unit=\"batch\") as tepoch:\n",
    "          for batch in tepoch:\n",
    "\n",
    "            images = batch[\"img\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "            ids = batch[\"idx\"].to('cpu').numpy()\n",
    "\n",
    "            outputs = net(images)\n",
    "            test_loss += criterion(outputs, labels)\n",
    "\n",
    "            labels = torch.argmax(labels, dim=1)\n",
    "            pred = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            test_correct += pred.eq(labels).sum().item()\n",
    "\n",
    "    test_loss /= len(test_dataloader.dataset)\n",
    "    test_accuracy = 100. * test_correct / len(test_dataloader.dataset)\n",
    "\n",
    "    print(\"[Epoch {}] Train Loss: {:.6f} - Test Loss: {:.6f} - Train Accuracy: {:.2f}% - Test Accuracy: {:.2f}%\".format(\n",
    "        epoch + 1, train_loss, test_loss, 100. * train_correct / len(train_dataloader.dataset), test_accuracy\n",
    "    ))\n",
    "\n",
    "    if test_accuracy > best_accuracy:\n",
    "        best_accuracy = test_accuracy\n",
    "        best_epoch = epoch\n",
    "\n",
    "        torch.save(net.state_dict(), \"best_model.pt\")\n",
    "\n",
    "print(\"\\nBEST TEST ACCURACY: \", best_accuracy, \" in epoch \", best_epoch)\n",
    "\n",
    "\n",
    "net.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "\n",
    "test_loss, test_correct = 0, 0\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    with tqdm(iter(test_dataloader), desc=\"Test \" + str(epoch), unit=\"batch\") as tepoch:\n",
    "        for batch in tepoch:\n",
    "\n",
    "            images = batch[\"img\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "            ids = batch[\"idx\"].to('cpu').numpy()\n",
    "\n",
    "            outputs = net(images)\n",
    "            test_loss += criterion(outputs, labels)\n",
    "\n",
    "            labels = torch.argmax(labels, dim=1)\n",
    "            pred = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            test_correct += pred.eq(labels).sum().item()\n",
    "\n",
    "    test_loss /= len(test_dataloader.dataset)\n",
    "    test_accuracy = 100. * test_correct / len(test_dataloader.dataset)\n",
    "print(\"Final best acc: \", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"Loading the best model for submission...\")\n",
    "net.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "net.eval()\n",
    "\n",
    "submission_data = {\n",
    "    \"ID\": [],\n",
    "    \"target\": [],\n",
    "}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader, desc=\"Generating Submission\"):\n",
    "        images = batch[\"img\"].to(device)\n",
    "        ids = batch[\"idx\"].to('cpu').numpy()\n",
    "        outputs = net(images)\n",
    "        pred = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "\n",
    "        submission_data[\"ID\"].extend(ids)\n",
    "        submission_data[\"target\"].extend(pred)\n",
    "\n",
    "submission_df = pd.DataFrame(submission_data)\n",
    "submission_df.sort_values(by=\"ID\", inplace=True)  \n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"Submission file 'submission.csv' generated.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
